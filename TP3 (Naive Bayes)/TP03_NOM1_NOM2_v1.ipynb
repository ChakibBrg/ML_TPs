{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2CSSID-TP03. Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "Dans ce TP, nous allons traiter Naive Bayes. C'est un modèle génératif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Binome 01** : Tirichine Mohammed\n",
    "- **Binome 02** : Bourzag Mohamed Chakib\n",
    "- **Groupe** : Il n'y a qu'un groupe => info inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.1', '2.1.2', '3.8.1')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy             as np\n",
    "import pandas            as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "np        .__version__ , \\\n",
    "pd        .__version__ , \\\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAPPEL**\n",
    "\n",
    "Tout le monde connait le théorème de Bayes pour calculer la probabilité conditionnelle d'un évennement $A$ sachant un autre $B$: \n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "Pour appliquer ce théorème sur un problème d'appentissage automatique, l'idée est simple ; Etant donné une caractéristique $f$ et la sortie $y$ qui peut avoir la classe $c$ : \n",
    "- Remplacer $A$ par $y=c$\n",
    "- Remplacer $B$ par $f$ \n",
    "On aura l'équation : \n",
    "$$ P(y=c|f) = \\frac{P(y=c)P(f|y=c)}{P(f)}$$\n",
    "\n",
    "On appelle : \n",
    "- $P(y=c|f)$ postérieure \n",
    "- $P(y=c)$ antérieure\n",
    "- $P(f|y=c)$ vraisemblance\n",
    "- $P(f)$ évidence \n",
    "\n",
    "Ici, on estime la probablité d'une classe $c$ sachant une caractéristique $f$ en utilisant des données d'entrainement. Maintenant, on veut estimer la probabilité d'une classe $c$ sachant un vecteur de caractéristiques $\\overrightarrow{f} = \\{f_1, ..., f_L\\}$ : \n",
    "$$ P(y=c|\\overrightarrow{f}) = \\frac{P(y=c)P(\\overrightarrow{f}|y=c)}{P(\\overrightarrow{f})}$$\n",
    "\n",
    "Etant donnée plusieurs classes $c_j$, la classe choisie $\\hat{c}$ est celle avec la probabilité maximale \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k|\\overrightarrow{f})$$\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\frac{P(y=c_k)P(\\overrightarrow{f}|y=c_k)}{P(\\overrightarrow{f})}$$\n",
    "On supprime l'évidence pour cacher le crime : $P(\\overrightarrow{f})$ ne dépend pas de $c_k$ et elle est postive, donc ça ne va pas affecter la fonction $\\max$.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k)P(\\overrightarrow{f}|y=c_k)$$\n",
    "\n",
    "Pour calculer $P(\\overrightarrow{f}|y=c_k)$, on va utiliser une properiété naïve (d'où vient le nom Naive Bayes) : on suppose l'indépendence conditionnelle entre les caractéristiques $f_j$. \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k) \\prod\\limits_{f_j \\in \\overrightarrow{f}} P(f_j|y=c_k)$$\n",
    "\n",
    "Pour éviter la disparition de la probabilité (multiplication et représentation de virgule flottante sur machine), on transforme vers l'espace logarithme.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Réalisation des algorithmes\n",
    "\n",
    "Pour estimer la vraisemblance, il existe plusieurs modèles (lois):\n",
    "- **Loi multinomiale :** pour les caracétristiques nominales\n",
    "- **Loi de Bernoulli :** lorsqu'on est interressé par l'apparence d'une caractéristique ou non (binaire)\n",
    "- **Loi normale :** pour les caractéristiques numériques\n",
    "\n",
    "Dans ce TP, nous allons implémenter Naive Bayes pour les caractéristiques nominales (loi multinomiale). \n",
    "Dans notre modèle, nous voulons stocker les statistiques et pas les probabilités. \n",
    "L'intérêt est de faciliter la mise à jours des statistiques (si par exemple, nous avons un autre dataset et nous voulons enrichir le modèle ; dans e cas, il suffit d'ajouter les statistiques du nouveau dataset)\n",
    "\n",
    "Ici, nous allons utiliser le dataset \"jouer\" (utilisé dans la plupart des cours) contenant des caractéristiques nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temps</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidite</th>\n",
       "      <th>vent</th>\n",
       "      <th>jouer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temps temperature humidite vent jouer\n",
       "0   ensoleile      chaude    haute  non   non\n",
       "1   ensoleile      chaude    haute  oui   non\n",
       "2     nuageux      chaude    haute  non   oui\n",
       "3    pluvieux       douce    haute  non   oui\n",
       "4    pluvieux     fraiche  normale  non   oui\n",
       "5    pluvieux     fraiche  normale  oui   non\n",
       "6     nuageux     fraiche  normale  oui   oui\n",
       "7   ensoleile       douce    haute  non   non\n",
       "8   ensoleile     fraiche  normale  non   oui\n",
       "9    pluvieux       douce  normale  non   oui\n",
       "10  ensoleile       douce  normale  oui   oui\n",
       "11    nuageux       douce    haute  oui   oui\n",
       "12    nuageux      chaude  normale  non   oui\n",
       "13   pluvieux       douce    haute  oui   non"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jouer   = pd.read_csv('data/jouer.csv')\n",
    "\n",
    "X_jouer = jouer.iloc[:, :-1].values # Premières colonnes \n",
    "Y_jouer = jouer.iloc[:,  -1].values # Dernière colonne \n",
    "\n",
    "# Afficher le dataset \"jouer\"\n",
    "jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Entraînement de la probabilité antérieure\n",
    "\n",
    "Etant donné le vecteur de sortie $Y$, la probabilité de chaque classe (différentes valeurs de $Y$) est calulée comme :\n",
    "\n",
    "$$p(c_k) = \\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
    "\n",
    "\n",
    "La fonction doit récupérer des statistiques afin de pouvoir calculer la probabilité antérieure de chaque classe. Donc, elle doit retourner  :\n",
    "- Un vecteur contenant les noms des classes\n",
    "- Un vecteur contenant les nombres d'occurrences de chaque classe dans le premier vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['non', 'oui'], dtype=object), array([5, 9]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Stastistiques sur la probabilité antérieure\n",
    "def stat_anterieure(Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    cls, counts = np.unique(Y, return_counts=True)\n",
    "    \n",
    "    return cls, counts.astype(int)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['non', 'oui'], dtype=object), array([5, 9]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "stat_anterieure(Y_jouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Entraînement de la probabilité de vraissemblance (loi multinomiale)\n",
    "\n",
    "Notre modèle doit garder le nombre des différentes valeurs d'une caractéristique $A$ et le nombre de ces valeurs dans chaque classe.\n",
    "Donc, étant donné un vecteur d'une caractéristique $A= X[:,j]$, un autre des $Y$ et un $C$ contenant la liste des classes, la fonction d'entraînement doit retourner : \n",
    "- $V$ : un vecteur contenant les différentes catégories de $A$ (c'est déjà fait)\n",
    "- Une matrice contenant le nombre d'occurrences de chaque catégorie de $V$ dans chaque classe  : \n",
    "   - Les lignes représentent les catégories $v \\in V$ de la caréctéristique $A$\n",
    "   - Les colonnes représentent les classes $c \\in C$ de $Y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       " array([[3, 2],\n",
       "        [0, 4],\n",
       "        [2, 3]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Statistiques de vraissemblance (une seule caractéristique)\n",
    "def stat_vraissemblance_1(A: np.ndarray, \n",
    "                          Y: np.ndarray, \n",
    "                          C: np.ndarray\n",
    "                         ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    V = np.unique(A) # Catégories de la caractéristique A\n",
    "    freq = np.zeros((len(V), len(C)))\n",
    "    d = np.concatenate((\n",
    "        np.array([np.where(V == ele) for ele in A]).reshape(-1, 1),\n",
    "        np.array([np.where(C == ele) for ele in Y]).reshape(-1, 1)\n",
    "    ), axis=1)\n",
    "\n",
    "    inds, counts = np.unique(d, axis=0, return_counts=True)\n",
    "    for i in range(len(inds)) :\n",
    "        freq[inds[i][0], inds[i][1]] = counts[i]\n",
    "    \n",
    "    return V, freq.astype(int)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#  array([[3, 2],\n",
    "#         [0, 4],\n",
    "#         [2, 3]]))\n",
    "#---------------------------------------------------------------------\n",
    "C_t = np.array(['non', 'oui'])\n",
    "stat_vraissemblance_1(X_jouer[:, 0], Y_jouer, C_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Entraînement loi multinomiale\n",
    "\n",
    "**Rien à programmer ici**\n",
    "\n",
    "Notre modèle ($\\theta_{X, C}$) doit garder des statistiques sur les classes et aussi sur chaque catégorie de chaque caractéristique. Pour ce faire, nous allons représenter $\\theta$ comme un vecteur : \n",
    "- $\\theta[N+1]$ est un vecteur de $N$ éléments représentant des statistiques sur chaque caractéristique $j$, plus un élément (le dernier) pour les statistiques sur les classes.\n",
    "- Chaque élément est un dictionnaire (HashMap en Java)\n",
    "- Un élément des caractéristiques contient deux clés : \n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe\n",
    "- Un élément des classes contient deux clés : \n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       "  'freq': array([[3, 2],\n",
       "         [0, 4],\n",
       "         [2, 3]])},\n",
       " {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
       "  'freq': array([[2, 2],\n",
       "         [2, 4],\n",
       "         [1, 3]])},\n",
       " {'val': array(['haute', 'normale'], dtype=object),\n",
       "  'freq': array([[4, 3],\n",
       "         [1, 6]])},\n",
       " {'val': array(['non', 'oui'], dtype=object),\n",
       "  'freq': array([[2, 6],\n",
       "         [3, 3]])},\n",
       " {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La fonction qui entraine Théta sur plusieurs caractéristiques\n",
    "# Rien à programmer ici\n",
    "# Notre théta est une liste des dictionnaires;\n",
    "# chaque dictionnaire contient la liste des catégories et la matrice des fréquences dela caractéristique respective à la colonne de X\n",
    "# On ajoute les statistiques antérieures des classes à la fin de résultat\n",
    "def entrainer_multi(X: np.ndarray, \n",
    "                    Y: np.ndarray\n",
    "                   ) -> np.ndarray: \n",
    "    \n",
    "    Theta   = []\n",
    "    \n",
    "    stats_c = {}\n",
    "    stats_c['cls'], stats_c['freq'] =  stat_anterieure(Y)\n",
    "    \n",
    "    for j in range(X.shape[1]): \n",
    "        stats = {}\n",
    "        stats['val'], stats['freq'] =  stat_vraissemblance_1(X[:, j], Y, stats_c['cls'])\n",
    "        Theta.append(stats)\n",
    "    \n",
    "    Theta.append(stats_c)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# [{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#   'freq': array([[3, 2],\n",
    "#          [0, 4],\n",
    "#          [2, 3]])},\n",
    "#  {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
    "#   'freq': array([[2, 2],\n",
    "#          [2, 4],\n",
    "#          [1, 3]])},\n",
    "#  {'val': array(['haute', 'normale'], dtype=object),\n",
    "#   'freq': array([[4, 3],\n",
    "#          [1, 6]])},\n",
    "#  {'val': array(['non', 'oui'], dtype=object),\n",
    "#   'freq': array([[2, 6],\n",
    "#          [3, 3]])},\n",
    "#  {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]\n",
    "#---------------------------------------------------------------------\n",
    "Theta_jouer = entrainer_multi(X_jouer, Y_jouer)\n",
    "\n",
    "Theta_jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Estimation de la probabilité de vraissemblance (loi multinomiale)\n",
    "L'équation pour estimer la vraisemblance \n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
    "\n",
    "\n",
    "Dans le cas d'une valeur $v$ qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donnée mais ui existe dans le dataset de test, nous aurons une probabilité nulle. \n",
    "Afin de régler ce problème, nous pouvons appliquer une fonction de lissage qui attribue une petite probabilité aux données non vues dans l'entraînement. \n",
    "Le lissage que nous allons utiliser est celui de Lidstone. \n",
    "Lorsque $\\alpha = 1$, il est appelé lissage de Laplace.\n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}| + \\alpha}{|\\{y = c_k\\}| + \\alpha * |V|}$$\n",
    "Où: \n",
    "- $\\alpha$ est une valeur donnée \n",
    "- $V$ est l'ensemble des différentes valeurs de $f_j$ (le vocabulaire; les catégories)\n",
    "\n",
    "Etant donné : \n",
    "- $\\theta_j$ les paramètres de la caractéristique $j$ représentées comme dictionnaire\n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique (vocabulaire $V$)\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe. C'est une matrice $|V|\\times|C|$\n",
    "- $v$ la valeur de la caractéristique $j$ utilisée pour calculer les probabilités\n",
    "- $\\theta_c$ les paramètres des classes $C$ représentées comme dictionnaire\n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences des classes\n",
    "    \n",
    "Cette fonction doit retourner : \n",
    "- Une liste $P[|C|]$ contenant les probabilités de la catégorie $v$ de $X_j$ sur toutes les classes $C$ \n",
    "- Elle doit prendre en considération le cas où la valeur $v$ n'existe pas dans le modèle entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculer la vraissamblance d'une valeur donnée\n",
    "def P_vraiss_multi(Theta_j: Dict[str, np.ndarray], \n",
    "                   Theta_c: Dict[str, np.ndarray], \n",
    "                   v      : str, \n",
    "                   alpha  : float = 0.\n",
    "                  ) -> np.ndarray: \n",
    "    \n",
    "    # une liste des indices où se trouve la valeur v dans Theta_j[\"val\"]\n",
    "    # ind est une liste vide s'il n'existe pas un element de Theta_j['val'] egale a v\n",
    "    # sinon, elle contient au moins une indice (dans notre cas, ecxactement un)\n",
    "    ind = np.where(Theta_j['val'] == v)[0]\n",
    "    p = []\n",
    "    for c in Theta_c['cls']:\n",
    "        cl_ind = np.where(Theta_c['cls'] == c)[0][0]\n",
    "        if len(ind) == 0:\n",
    "            p.append(alpha / (Theta_c['freq'][cl_ind] + alpha * len(Theta_j['val'])))\n",
    "        else:\n",
    "            p.append((Theta_j['freq'][ind[0]][cl_ind] + alpha) / (Theta_c['freq'][cl_ind] + alpha * len(Theta_j['val'])))\n",
    "    return np.array(p)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))\n",
    "#---------------------------------------------------------------------\n",
    "# Calcul :\n",
    "# La probabilité de jouer si temps = pluvieux \n",
    "# P(temps = pluvieux | jouer=oui) = (nbr(temps=pluvieux et jouer=oui)+alpha)/(nbr(jour=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = pluvieux | jouer=oui) = (3 + 0)/(9 + 0) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = pluvieux | jouer=oui) = 4/12 ==> 0.33333333333333333333333333333333333~\n",
    "\n",
    "# La probabilité de jouer si temps = neigeux \n",
    "# P(temps = neigeux | jouer=oui) = (nbr(temps=neigeux et jouer=oui)+alpha)/(nbr(jouer=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = neigeux | jouer=oui) = (0 + 1)/(9 + 3) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = neigeux | jouer=oui) = 1/13 ==> 0.0833333333333333333333333333333333333~\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'pluvieux'), \\\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'neigeux', alpha=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5. Prédiction de la classe (loi multinomiale)\n",
    "Revenons maintenant à notre équation de prédiction \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
    "\n",
    "- On doit prédire un seule échantillon $x$. \n",
    "- La fonction doit retourner un vecteur des log-probabilité des classes\n",
    "- Si anter=false donc on n'utilise pas la probabilité antérieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Prédiction des log des probabilités\n",
    "def predire(x    : np.ndarray, \n",
    "            Theta: List[Dict[str, np.ndarray]], \n",
    "            alpha: float = 1., \n",
    "            anter: bool  = True\n",
    "           ) -> float:\n",
    "    p = []\n",
    "    for c in range(len(Theta[-1]['cls'])):\n",
    "        p.append(np.log(Theta[-1]['freq'][c] / np.sum(Theta[-1]['freq'])) if anter else 0)\n",
    "        for j in range(len(x)):\n",
    "            p[-1] += np.log(P_vraiss_multi(Theta[j], Theta[-1], x[j], alpha)[c])\n",
    "    return np.array(p)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))\n",
    "#---------------------------------------------------------------------\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer), \\\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer, anter=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6. Regrouper en une classe (loi multinomiale)\n",
    "\n",
    "**Rien à programmer ici**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oui', 'non']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NBMultinom(object): \n",
    "    \n",
    "    def __init__(self, alpha=1.): \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def entrainer(self, X, Y):\n",
    "        self.Theta = entrainer_multi(X, Y)\n",
    "    \n",
    "    def predire(self, X, anter=True, prob=False): \n",
    "        Y_pred = []\n",
    "        cls = self.Theta[-1]['cls']\n",
    "        for i in range(len(X)): \n",
    "            log_prob = predire(X[i,:], self.Theta, alpha=self.alpha, anter=anter)\n",
    "            if prob:\n",
    "                Y_pred.append(np.max(log_prob))\n",
    "            else:\n",
    "                Y_pred.append(cls[np.argmax(log_prob)])\n",
    "        return Y_pred\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# ['oui', 'non']\n",
    "#---------------------------------------------------------------------\n",
    "notre_modele = NBMultinom()\n",
    "notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "X_test = np.array([\n",
    "    ['neigeux', 'fraiche', 'normale', 'oui'],\n",
    "    ['neigeux', 'fraiche', 'haute'  , 'oui']\n",
    "])\n",
    "notre_modele.predire(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application et analyse\n",
    "\n",
    "**Il n'y a rien à programmer ici.**\n",
    "\n",
    "Le but de cette section est de mener des expérimentations afin de bien comprendre les concepts vus dans le cours.\n",
    "Aussi, elle nous assiste à comprendre l'effet des différents paramètres.\n",
    "En plus, la discussion des différentes expérimentations peut améliorer l'aspect analytique chez l'étudient.\n",
    "\n",
    "### II.1. Probabilité antérieure \n",
    "\n",
    "Nous voulons tester l'effet de la probabilité antérieure.\n",
    "Pour ce faire, nous avons entraîné deux modèles :\n",
    "1. Avec probabilité antérieure\n",
    "1. Sans probabilité antérieure (Il considère une distribution uniforme des classes)\n",
    "\n",
    "Pour tester si les modèles ont bien s'adapter au dataset d'entraînement, nous allons les tester sur le même dataset et calculer le rapport de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec probabilité antérieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Sans probabilité antérieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       0.67      0.80      0.73         5\n",
      "         oui       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.77      0.79      0.78        14\n",
      "weighted avg       0.80      0.79      0.79        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AVEC Scikit-learn\n",
    "# ===================\n",
    "from sklearn.naive_bayes   import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics       import classification_report\n",
    "\n",
    "nb_avec     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
    "nb_sans     = CategoricalNB(alpha=1.0, fit_prior=False)\n",
    "\n",
    "enc         = OrdinalEncoder()\n",
    "X_jouer_enc = enc.fit_transform(X_jouer)\n",
    "nb_avec.fit(X_jouer_enc, Y_jouer)\n",
    "nb_sans.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "Y_pred_avec = nb_avec.predict(X_jouer_enc)\n",
    "Y_pred_sans = nb_sans.predict(X_jouer_enc)\n",
    "\n",
    "# AVEC notre modèle (juste pour voir comment l'utiliser)\n",
    "# =======================================================\n",
    "#notre_modele = NBMultinom()\n",
    "#notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "#Y_notre_ant = notre_modele.predire(X_jouer)\n",
    "#Y_notre_sans_ant = notre_modele.predire(X_jouer, anter=False) \n",
    "\n",
    "# Le rapport de classification\n",
    "\n",
    "\n",
    "print( 'Avec probabilité antérieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_avec))\n",
    "\n",
    "print( 'Sans probabilité antérieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_sans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "    \n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que la probabilité antérieure est importante dans ce cas ?\n",
    "- Comment cette probabilité affecte le résultat ?\n",
    "- Quand est-ce que nous sommes sûrs que l'utilisation de cette probabilité est inutile ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- ... Le modèle avec probabilité antérieure a un meilleur score que celui sans probabilité antérieure\n",
    "- ... Oui\n",
    "- ... Elle augmente la probabilité de la classe la plus probable\n",
    "- ... Quand les classes sont équilibrées, ce qui veut dire que c'est une probabilité uniforme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Lissage\n",
    "\n",
    "Nous voulons tester l'effet de lissage de Lidstone.\n",
    "Pour ce faire, nous avons entraîné trois modèles : \n",
    "1. alpha = 1 (lissage de Laplace)\n",
    "1. alpha = 0.5\n",
    "1. alpha = 0 (sans lissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Education\\2CS\\ML_TPs\\venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "d:\\Education\\2CS\\ML_TPs\\venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
    "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
    "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
    "\n",
    "NBC_10.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_05.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_00.fit( X_jouer_enc,   Y_jouer )\n",
    "\n",
    "Y_10   = NBC_10.predict(X_jouer_enc)\n",
    "Y_05   = NBC_05.predict(X_jouer_enc)\n",
    "Y_00   = NBC_00.predict(X_jouer_enc)\n",
    "\n",
    "\n",
    "print(          'Alpha = 1.0'             )\n",
    "print(classification_report(Y_jouer, Y_10))\n",
    "\n",
    "print(          'Alpha = 0.5'             )\n",
    "print(classification_report(Y_jouer, Y_05))\n",
    "\n",
    "print(          'Alpha = 0.0'             )\n",
    "print(classification_report(Y_jouer, Y_00))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que le lissage affecte la performance dans ce cas ? Pourquoi ?\n",
    "- Pourquoi Scikit-learn n'accepte pas la valeur $\\alpha=0$ et affiche une alerte \"UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\" ?\n",
    "- Quelle est l'intérêt du lissage (dans le cas général) ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- ... Y a pas de différence entre les trois modèles\n",
    "- ... Non, car le test est sur le même dataset d'entraînement donc toutes les valeurs de $v$ existent dans le modèle\n",
    "- ... Car la probabilité des valeurs non vues sera nulle\n",
    "- ... Pour éviter le sur-apprentissage, car le modèle ne sera pas capable de généraliser en dehor de la dataset d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Comparaison avec d'autres algorithmes\n",
    "\n",
    "Naive Bayes est un algorithme puissant lorsqu'il s'agit de classer les documents textuels ; nous voulons tester cette information avec la détection de spam. \n",
    "Le dataset utilisé est [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
    "Chaque message du dataset doit être représenté sous forme d'un modèle \"Sac à mots\" (BoW : Bag of Words).\n",
    "Dans l'entraînement, les différents mots qui s'apparaissent dans les messages (vocabulaire) sont considérés comme des caractéristiques. \n",
    "Donc, pour chaque message, la valeur de la caractéristique est la fréquence du mot dans le message. \n",
    "Par exemple, si le mot \"good\" apparait 3 fois dans le message, donc la caractéristique \"good\" aura la valeur 3 dans ce message.\n",
    "\n",
    "Notre implémentation n'est pas adéquate pour la nature de ce problème. \n",
    "Dans Scikit-learn, [sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) est similaire à notre implémentation. \n",
    "L'algorithme adéquat pour ce type de problème est [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "Les algorithmes comparés :\n",
    "1. Naive Bayes (Loi Multinomiale)\n",
    "1. Naive Bayes (Loi Gaussienne)\n",
    "1. Regression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texte classe\n",
       "0  Go until jurong point, crazy.. Available only ...    ham\n",
       "1                      Ok lar... Joking wif u oni...    ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
       "3  U dun say so early hor... U c already then say...    ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...    ham"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lire le dataset\n",
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "# renomer les caractéristiques : texte et classe\n",
    "messages = messages.rename(columns={'v1': 'classe', 'v2': 'texte'})\n",
    "# garder seulement ces deux caractéristiques\n",
    "messages = messages.filter(['texte', 'classe'])\n",
    "\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.metrics                 import precision_score, recall_score\n",
    "import timeit\n",
    "\n",
    "\n",
    "modeles = [\n",
    "    MultinomialNB(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(solver='lbfgs') \n",
    "    #solver=sag est plus lent; donc j'ai choisi le plus rapide\n",
    "]\n",
    "\n",
    "temps_train = []\n",
    "temps_test  = []\n",
    "rappel      = []\n",
    "precision   = []\n",
    "\n",
    "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['texte'] ,\n",
    "                                                        messages['classe'],\n",
    "                                                        test_size    = 0.2, \n",
    "                                                        random_state = 0  )\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
    "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
    "\n",
    "\n",
    "for modele in modeles:\n",
    "    # ==================================\n",
    "    # ENTRAINEMENT \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    modele.fit(X_train, Y_train)\n",
    "    temps_train.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # TEST \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    Y_pred      = modele.predict(X_test)\n",
    "    temps_test.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # PERFORMANCE \n",
    "    # ==================================\n",
    "    # Ici, nous considérons une classification binaire avec une seule classe \"spam\" \n",
    "    # le classifieur ne sera pas jugé par sa capacité de détecter les non spams\n",
    "    precision.append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
    "    rappel   .append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
    "\n",
    "    \n",
    "print('Fin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.1. Temps d'entraînement et de test\n",
    "\n",
    "Combien de temps chaque algorithme prend pour entrainer le même dataset d'entrainement et combien de temps pour tester le même dataset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Temps d'entrainement</th>\n",
       "      <th>Temps de test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>0.015333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien</td>\n",
       "      <td>0.303610</td>\n",
       "      <td>0.064949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique</td>\n",
       "      <td>0.793461</td>\n",
       "      <td>0.017584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithme  Temps d'entrainement  Temps de test\n",
       "0  Naive Bayes Multinomial              0.250683       0.015333\n",
       "1     Naive Bayes Gaussien              0.303610       0.064949\n",
       "2    Regression logistique              0.793461       0.017584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_noms = ['Naive Bayes Multinomial', 'Naive Bayes Gaussien', 'Regression logistique']\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Algorithme'            : algo_noms  ,\n",
    "    'Temps d\\'entrainement' : temps_train,\n",
    "    'Temps de test'         : temps_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "- Que remarquez-vous concernant le temps d'entrainement ? (ordonner les algorithmes)\n",
    "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps d'entrainement)\n",
    "- Que remarquez-vous concernant le temps de test ? (ordonner les algorithmes)\n",
    "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps de test)\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- ... Le temps d'entraînement est le plus petit pour la régression logistique, puis Naive Bayes (loi multinomiale) et enfin Naive Bayes (loi gaussienne)\n",
    "- ... La régression logistique est plus lente car elle est une méthode d'optimisation itérative alors que les méthodes Naive Bayes sont des solutions directes, et Naive Bayes (loi gaussienne) est plus lente que Naive Bayes (loi multinomiale) car elle calcule la moyenne et la variance de chaque caractéristique.\n",
    "- ... Le temps de test est le plus petit pour Naive Bayes (loi multinomiale), puis la régression logistique et enfin Naive Bayes (loi gaussienne).\n",
    "- ... Naive Bayes (loi multinomiale) est plus rapide que les autres car elle ne calcule que la probabilité de chaque classe, et la Regression Logistique est plus rapide que Naive Bayes (loi gaussienne) car elle ne calcule que le produit scalaire entre les caractéristiques et les poids, alors que Naive Bayes (loi gaussienne) calcule la densité de probabilité gaussienne pour chaque caractéristique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.2. Qualité de prédiction\n",
    "\n",
    "Comment chaque algorithme performe sur le dataset de test dans le cas de détection de spams (spam: est la classe positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Rappel</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithme    Rappel  Precision\n",
       "0  Naive Bayes Multinomial  0.927711   0.987179\n",
       "1     Naive Bayes Gaussien  0.891566   0.616667\n",
       "2    Regression logistique  0.855422   0.986111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Algorithme' : algo_noms,\n",
    "    'Rappel'     : rappel   ,\n",
    "    'Precision'  : precision\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "On remarque que Naive Bayes surpasse la régression logistique pour la détection de spams. \n",
    "- Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème ?\n",
    "- Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires ?\n",
    "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature des deux algorithmes ?\n",
    "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature du probleme/donnees ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- Non\n",
    "- Oui\n",
    "- ... Car la méthode gaussienne stipule que les caractéristiques suivent une distribution gaussienne, ce qui n'est pas forcément le cas dans ce problème\n",
    "- ... Car les caractéristiques sont des mots, et la distribution gaussienne n'est pas adaptée pour les mots (les mots sont des valeurs discrètes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  _____    __                                              _               \n",
      " |_   _|  / _|                                            | |              \n",
      "   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \n",
      "   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \n",
      "  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \n",
      " |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \n",
      "                   __/ |                     __/ |                         \n",
      "                  |___/                     |___/                          \n",
      "  _     _       _            __                                            \n",
      " | |   | |     (_)          / _|                 _                         \n",
      " | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \n",
      " | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \n",
      " | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \n",
      "  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \n",
      "                                                |/                         \n",
      "                                                                           \n",
      "                                                                           \n",
      "                                                                           \n",
      "  _   _    ___    _   _      __ _   _ __    ___                            \n",
      " | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \n",
      " | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \n",
      "  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \n",
      "   __/ |                                                                   \n",
      "  |___/                                                                    \n",
      "                    _                                                __    \n",
      "                   | |                                            _  \\ \\   \n",
      "  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \n",
      " | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \n",
      " | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \n",
      " |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \n",
      "                                                                     /_/   \n",
      "                                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\_'\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:6: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:13: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:14: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:20: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:22: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:26: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"                   | |                                            _  \\ \\   \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:28: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
      "C:\\Users\\mohti\\AppData\\Local\\Temp\\ipykernel_12544\\4210918688.py:30: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n"
     ]
    }
   ],
   "source": [
    "print(\"  _____    __                                              _               \")\n",
    "print(\" |_   _|  / _|                                            | |              \")\n",
    "print(\"   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \")\n",
    "print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
    "print(\"  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \")\n",
    "print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
    "print(\"                   __/ |                     __/ |                         \")\n",
    "print(\"                  |___/                     |___/                          \")\n",
    "print(\"  _     _       _            __                                            \")\n",
    "print(\" | |   | |     (_)          / _|                 _                         \")\n",
    "print(\" | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \")\n",
    "print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
    "print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
    "print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
    "print(\"                                                |/                         \")\n",
    "print(\"                                                                           \")\n",
    "print(\"                                                                           \")\n",
    "print(\"                                                                           \")\n",
    "print(\"  _   _    ___    _   _      __ _   _ __    ___                            \")\n",
    "print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
    "print(\" | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \")\n",
    "print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
    "print(\"   __/ |                                                                   \")\n",
    "print(\"  |___/                                                                    \")\n",
    "print(\"                    _                                                __    \")\n",
    "print(\"                   | |                                            _  \\ \\   \")\n",
    "print(\"  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \")\n",
    "print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
    "print(\" | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \")\n",
    "print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n",
    "print(\"                                                                     /_/   \")\n",
    "print(\"                                                                           \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
